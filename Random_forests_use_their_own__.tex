Random forests use their own form of cross-validation by training and testing each tree using a different bootstrapped sample from the data. This process produces an \emph{out-of-bag error (oob)} that acts as a generalized error for understanding how well each class can be predicted. A major benefit and 