\subsection{Discussion}
\label{sec:scalabilitydiscussion}

Mean accuracy of multi-label classification models as done in this analysis is a harsh metric as it forces the model to make a single choice for labeling each sample. In practice, we would not want a model that completely makes this decision; we would simply want the model to inform us what the probability that a sample fits within a class. For example, there could be 45\% chance an unlabeled account is an office, a 35\% chance it is a school and 20\% chance it is a grocery store. The reason we choose mean model accuracy in this report it to communicate a simplified message of the techniques and the progress weâ€™ve made thus far. The fact that the overall classification model accuracy is around 40-60\% for a classification model with ten classes is not discouraging. It is the improvement in mean accuracy from baselines that is the focus and this has been demonstrated so far in the project. Additionally, there are other classification metrics including precision, recall, and F-Score that we have left out from this report that can be used to determine model usefulness. 

We can also see in detail how the model predicts the classes for each by creating and analyzing a classification confusion matrix. Figure 3 illustrates this matrix for the combined model. We can observe that two of the largest classes, Retail and Finance, have the highest accuracy rates at over 55-60\% with several other categories being misclassified within them.  This issue is common with imbalanced classification models and further feature development would improve the model by better characterizing the difference between each class.


This project has created additional information about AMI accounts by extracting characteristics from the high-frequency time-series AMI measurements. Based on a classification test using almost 9,600 labeled smart meter accounts, we improved the accuracy of predicting building type (based on SIC 1-Digit category) by over 27\% over a conventional baseline. 

We then aggregated data about measures implementation from the KITT database and classified almost 1,600 accounts into Good, Average, and Poor performing classes according to pre and post-measure consumption. A classification model was developed using the KITT and AMI information that improved the ability to predict measure implementation class success by 18\% over a baseline. Additionally, there was only a 20\% error rate in differentiating between Good and Poor performing measures.

The biggest opportunity ahead is to apply the generated models to the 30,000+ unlabeled SMB AMI accounts to help characterize missing meta-data and predict measure implementation success for future projects. Much work is also yet to be done to improve the models and input information to bring the overall prediction accuracies higher in absolute terms. Model prediction can also be improved incrementally as the AMI and KITT Databases grow and better data integration is achieved. A promising area in prediction accuracy is in the use of better daily and weekly pattern recognition techniques.
